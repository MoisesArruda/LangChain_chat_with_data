{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import List\n",
    "import datetime\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O sistema n�o pode encontrar o caminho especificado.\n"
     ]
    }
   ],
   "source": [
    "!(app\\chatbot\\chatbot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat(t=0.0):\n",
    "    \"\"\"\n",
    "    Configura os objetos do AzureChatOpenAI para serem utilizados.\n",
    " \n",
    "    Args:\n",
    "        t (float): O valor da temperatura para determinar o comportamento da resposta, por padrão é 0.0.\n",
    "   \n",
    "    Returns:\n",
    "        AzureChatOpenAI: O objeto de AzureChatOpenAi configurado.\n",
    "    \"\"\"\n",
    "    llm_chat = AzureChatOpenAI(openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "                    openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "                    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                    openai_api_type=os.getenv(\"OPENAI_API_TYPE\"),\n",
    "                    deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "                    temperature=t\n",
    "    )\n",
    "    return llm_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pdfs\n",
    "loaders = [\n",
    "    PyPDFLoader(r'C:\\AI\\Cursos\\LangChain_Chat_Data\\data\\Docker_para_desenvolvedores.pdf'),\n",
    "           PyPDFLoader(r'C:\\AI\\Cursos\\LangChain_Chat_Data\\data\\Containers_com_Docker.pdf')\n",
    "        ]   \n",
    "           \n",
    "docs = []\n",
    "\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "# Total de chunks\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings():\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        deployment = os.getenv(\"EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = create_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008\n"
     ]
    }
   ],
   "source": [
    "# Armazenamento no VectorDB\n",
    "vectordb = Chroma.from_documents(\n",
    "    \n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    #persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"O que é um docker compose e como configura-lo?\"\n",
    "\n",
    "# Busca por similaridades\n",
    "docs = vectordb.similarity_search(query,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = create_chat()\n",
    "llm.predict(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir o prompt para auxiliar o modelo na forma e nas informações auxiliares que ajudarão a responder as perguntas.\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "context: {context}\n",
    "question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate(template=template,input_variables=['context','question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever = vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    # Passando a estrutura que irá auxiliar\n",
    "    chain_type_kwargs={'prompt':prompt}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"O que é um docker compose e como configura-lo?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Docker Compose é uma ferramenta para definição e execução de múltiplos containers Docker, permitindo configurar todos os parâmetros necessários para executar cada container a partir de um arquivo de definição. Esse arquivo é escrito seguindo o formato YAML e pode especificar serviços, volumes e redes a serem criados. A indentação é um fator importante na definição do arquivo e cada linha pode ser definida com uma chave valor ou uma lista. Thanks for asking!'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain({'query':question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"O que é uma imagem?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No contexto do Docker, uma imagem é uma abstração da infraestrutura em estado somente leitura, a partir da qual será instanciado um container. É como se fosse uma classe em orientação a objetos, enquanto o container seria um objeto. Toda vez que um container é iniciado, ele é iniciado a partir de uma imagem. As imagens podem ser oficiais ou não oficiais e podem ser personalizadas para atender às necessidades específicas de um projeto.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Como posso criar uma?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Para criar uma imagem no Docker, você precisa criar um arquivo chamado Dockerfile que descreve as etapas necessárias para construir a imagem. O Dockerfile contém uma série de instruções que o Docker segue para criar a imagem. Depois de criar o Dockerfile, você pode usar o comando \"docker build\" para criar a imagem. Certifique-se de estar no diretório onde o Dockerfile está localizado e execute o comando \"docker build -t nome_da_imagem .\" (o ponto no final indica que o Docker deve usar o diretório atual como contexto para a construção da imagem).'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
